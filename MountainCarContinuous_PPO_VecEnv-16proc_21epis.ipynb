{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MountainCarContinuous-v0 with PPO, Vectorized Environment\n",
    "\n",
    "\n",
    "### 1. Create Vectorized Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gym version:  0.22.0\n",
      "torch version:  2.5.1\n",
      "device:  cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_steps:  999\n",
      "threshold:  99.0\n",
      "reassigned threshold:  2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from  collections  import deque\n",
    "import time\n",
    "from model import Policy\n",
    "from ppo import ppo_agent\n",
    "from storage import RolloutStorage\n",
    "from utils import get_render_func, get_vec_normalize\n",
    "from envs import make_vec_envs\n",
    "from parallelEnv import parallelEnv\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print('gym version: ', gym.__version__)\n",
    "print('torch version: ', torch.__version__)\n",
    "\n",
    "seed = 0 \n",
    "gamma=0.99\n",
    "num_processes =  16 \n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "print('device: ', device)\n",
    "\n",
    "envs = parallelEnv('MountainCarContinuous-v0', n=num_processes, seed=seed)\n",
    "\n",
    "## make_vec_envs -cannot find context for 'forkserver'\n",
    "## forkserver is only available in Python 3.4+ and only on some Unix platforms (not on Windows).\n",
    "## envs = make_vec_envs('BipedalWalker-v2', \\\n",
    "##                    seed + 1000, num_processes,\n",
    "##                    None, None, False, device='cpu', allow_early_resets=False)\n",
    "\n",
    "max_steps = envs.max_steps\n",
    "print('max_steps: ', max_steps)\n",
    "\n",
    "threshold = envs.threshold\n",
    "print('threshold: ', threshold)\n",
    "threshold = 2000\n",
    "print('reassigned threshold: ', threshold)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "dir_chk = 'dir_save_test'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Instantiate Model, Agent and Storage\n",
    "\n",
    "Initialize the Policy (model MLPBase), PPO Agent and Rollout Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type obs:  <class 'numpy.ndarray'> , shape obs:  (16, 2)\n",
      "type obs_t:  <class 'torch.Tensor'> , shape obs_t:  torch.Size([16, 2])\n"
     ]
    }
   ],
   "source": [
    "## model Policy uses MLPBase\n",
    "# policy = Policy(envs.observation_space.shape, envs.action_space,\\\n",
    "#         base_kwargs={'recurrent': False})\n",
    "\n",
    "# 修改policy\n",
    "policy = Policy(envs.observation_space.shape, envs.action_space,\\\n",
    "        base_kwargs={'recurrent': False})\n",
    "\n",
    "policy.to(device)\n",
    "\n",
    "agent = ppo_agent(actor_critic=policy, ppo_epoch=16, num_mini_batch=16,\\\n",
    "                 lr=0.01, eps=1e-5, max_grad_norm=0.5)\n",
    "\n",
    "rollouts = RolloutStorage(num_steps=max_steps, num_processes=num_processes, \\\n",
    "                        obs_shape=envs.observation_space.shape, action_space=envs.action_space, \\\n",
    "                        recurrent_hidden_state_size=policy.recurrent_hidden_state_size)\n",
    "\n",
    "obs = envs.reset()\n",
    "print('type obs: ', type(obs), ', shape obs: ', obs.shape)\n",
    "obs_t = torch.tensor(obs)\n",
    "print('type obs_t: ', type(obs_t), ', shape obs_t: ', obs_t.shape)\n",
    "\n",
    "rollouts.obs[0].copy_(obs_t)\n",
    "rollouts.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Save model function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(model, directory, filename, suffix):\n",
    "    torch.save(model.base.actor.state_dict(), '%s/%s_actor_%s.pth' % (directory, filename, suffix))\n",
    "    torch.save(model.base.critic.state_dict(), '%s/%s_critic_%s.pth' % (directory, filename, suffix))\n",
    "    torch.save(model.base.critic_linear.state_dict(), '%s/%s_critic_linear_%s.pth' % (directory, filename, suffix))\n",
    "    torch.save(model.base, '%s/%s_model_base_%s.pth' % (directory, filename, suffix))\n",
    "    torch.save(model.dist, '%s/%s_model_dist_%s.pth' % (directory, filename, suffix))\n",
    "    \n",
    "limits = [-300, -160, -100, -70, -50, 0, 20, 30, 40, 60, 90, 120, 150, 180, 210, 240, 270, 300, 330]\n",
    "\n",
    "def return_suffix(j):\n",
    "    suf = '0'\n",
    "    for i in range(len(limits)-1):\n",
    "        if j > limits[i] and j < limits[i+1]:\n",
    "            suf = str(limits[i+1])\n",
    "            break\n",
    "        \n",
    "        i_last = len(limits)-1    \n",
    "        if  j > limits[i_last]:\n",
    "            suf = str(limits[i_last])\n",
    "            break\n",
    "    return suf      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train the Agent  with Vectorized Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_updates=120\n",
    "gamma = 0.99\n",
    "tau=0.95\n",
    "save_interval=30\n",
    "log_interval= 1 \n",
    "\n",
    "def ppo_vec_env_train(envs, agent, policy, num_processes, num_steps, rollouts):\n",
    "    \n",
    "    time_start = time.time()\n",
    "    \n",
    "    n=len(envs.ps)    \n",
    "    envs.reset()\n",
    "    \n",
    "    # start all parallel agents\n",
    "    print('Number of agents: ', n)\n",
    "    envs.step([[1]*4]*n)\n",
    "    \n",
    "    indices = []\n",
    "    for i  in range(n):\n",
    "        indices.append(i)\n",
    "     \n",
    "    s = 0\n",
    "    \n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores_array = []\n",
    "    avg_scores_array = []    \n",
    "\n",
    "    for i_episode in range(num_updates):\n",
    "        \n",
    "        total_reward = np.zeros(n)\n",
    "        timestep = 0\n",
    "        \n",
    "        done = False\n",
    "        \n",
    "        for timestep in range(num_steps):\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                value, actions, action_log_prob, recurrent_hidden_states = \\\n",
    "                   policy.act(\n",
    "                        rollouts.obs[timestep],\n",
    "                        rollouts.recurrent_hidden_states[timestep],\n",
    "                        rollouts.masks[timestep])\n",
    "                   \n",
    "                \n",
    "            obs, rewards, done, _ = envs.step(actions.cpu().detach().numpy())\n",
    "            \n",
    "            \n",
    "            total_reward += rewards  ## this is the list by agents\n",
    "                        \n",
    "            # If done then clean the history of observations.\n",
    "            masks = torch.FloatTensor([[0.0] if done_ else [1.0] for done_ in done])\n",
    "            obs_t = torch.tensor(obs)\n",
    "            \n",
    "            ## Add one dimnesion to tensor, \n",
    "            ## This is (unsqueeze(1)) solution for:\n",
    "            ## RuntimeError: The expanded size of the tensor (1) must match the existing size...\n",
    "            rewards_t = torch.tensor(rewards).unsqueeze(1)\n",
    "            rollouts.insert(obs_t, recurrent_hidden_states, actions, action_log_prob, \\\n",
    "                value, rewards_t, masks)\n",
    "                                \n",
    "        avg_total_reward = np.mean(total_reward)\n",
    "        scores_deque.append(avg_total_reward)\n",
    "        scores_array.append(avg_total_reward)\n",
    "                \n",
    "        with torch.no_grad():\n",
    "            next_value = policy.get_value(rollouts.obs[-1],\n",
    "                            rollouts.recurrent_hidden_states[-1],\n",
    "                            rollouts.masks[-1]).detach()\n",
    "\n",
    "        rollouts.compute_returns(next_value, gamma, tau)\n",
    "        \n",
    "        agent.update(rollouts)\n",
    "        # 改动了一下update\n",
    "        # agent.update(rollouts, i_episode)\n",
    "\n",
    "        rollouts.after_update()\n",
    "        \n",
    "        avg_score = np.mean(scores_deque)\n",
    "        avg_scores_array.append(avg_score)\n",
    "\n",
    "        if i_episode > 0 and i_episode % save_interval == 0:\n",
    "            print('Saving model, i_episode: ', i_episode, '\\n')\n",
    "            suf = return_suffix(avg_score)\n",
    "            save(policy, dir_chk, 'we0', suf)\n",
    "\n",
    "        \n",
    "        if i_episode % log_interval == 0 and len(scores_deque) > 1:            \n",
    "            prev_s = s\n",
    "            s = (int)(time.time() - time_start)\n",
    "            t_del = s - prev_s\n",
    "            print('Ep. {}, Timesteps {}, Score.Agents: {:.2f}, Avg.Score: {:.2f}, Time: {:02}:{:02}:{:02}, \\\n",
    "Interval: {:02}:{:02}'\\\n",
    "                   .format(i_episode, timestep+1, \\\n",
    "                        avg_total_reward, avg_score, s//3600, s%3600//60, s%60, t_del%3600//60, t_del%60)) \n",
    "    \n",
    "        if len(scores_deque) > 1 and avg_score > threshold:   \n",
    "            print('Environment solved with Average Score: ',  avg_score )\n",
    "            break\n",
    "        \n",
    "    \n",
    "    return scores_array, avg_scores_array\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Process Process-16:\n",
      "Process Process-14:\n",
      "Process Process-13:\n",
      "Process Process-15:\n",
      "Process Process-12:\n",
      "Process Process-11:\n",
      "Process Process-9:\n",
      "Process Process-10:\n",
      "Process Process-4:\n",
      "Process Process-3:\n",
      "Process Process-6:\n",
      "Process Process-2:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mapleleaf/Downloads/RL/Deep-Reinforcement-Learning-Algorithms/MountainCarContinuous_PPO/parallelEnv.py\", line 111, in worker\n",
      "    cmd, data = remote.recv()\n",
      "                ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 249, in recv\n",
      "    buf = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 413, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 382, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mapleleaf/Downloads/RL/Deep-Reinforcement-Learning-Algorithms/MountainCarContinuous_PPO/parallelEnv.py\", line 111, in worker\n",
      "    cmd, data = remote.recv()\n",
      "                ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 249, in recv\n",
      "    buf = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 413, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 382, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n",
      "Traceback (most recent call last):\n",
      "Process Process-1:\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mapleleaf/Downloads/RL/Deep-Reinforcement-Learning-Algorithms/MountainCarContinuous_PPO/parallelEnv.py\", line 111, in worker\n",
      "    cmd, data = remote.recv()\n",
      "                ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 249, in recv\n",
      "    buf = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 413, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 382, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mapleleaf/Downloads/RL/Deep-Reinforcement-Learning-Algorithms/MountainCarContinuous_PPO/parallelEnv.py\", line 111, in worker\n",
      "    cmd, data = remote.recv()\n",
      "                ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 249, in recv\n",
      "    buf = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 413, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 382, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mapleleaf/Downloads/RL/Deep-Reinforcement-Learning-Algorithms/MountainCarContinuous_PPO/parallelEnv.py\", line 111, in worker\n",
      "    cmd, data = remote.recv()\n",
      "                ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 249, in recv\n",
      "    buf = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 413, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 382, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n",
      "Process Process-5:\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mapleleaf/Downloads/RL/Deep-Reinforcement-Learning-Algorithms/MountainCarContinuous_PPO/parallelEnv.py\", line 111, in worker\n",
      "    cmd, data = remote.recv()\n",
      "                ^^^^^^^^^^^^^\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 249, in recv\n",
      "    buf = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 413, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 382, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n",
      "Process Process-7:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mapleleaf/Downloads/RL/Deep-Reinforcement-Learning-Algorithms/MountainCarContinuous_PPO/parallelEnv.py\", line 111, in worker\n",
      "    cmd, data = remote.recv()\n",
      "                ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 249, in recv\n",
      "    buf = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 413, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 382, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n",
      "Process Process-8:\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mapleleaf/Downloads/RL/Deep-Reinforcement-Learning-Algorithms/MountainCarContinuous_PPO/parallelEnv.py\", line 111, in worker\n",
      "    cmd, data = remote.recv()\n",
      "                ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 249, in recv\n",
      "    buf = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 413, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 382, in _recv\n",
      "    raise EOFError\n",
      "Traceback (most recent call last):\n",
      "EOFError\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mapleleaf/Downloads/RL/Deep-Reinforcement-Learning-Algorithms/MountainCarContinuous_PPO/parallelEnv.py\", line 111, in worker\n",
      "    cmd, data = remote.recv()\n",
      "                ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 249, in recv\n",
      "    buf = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 413, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 382, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mapleleaf/Downloads/RL/Deep-Reinforcement-Learning-Algorithms/MountainCarContinuous_PPO/parallelEnv.py\", line 111, in worker\n",
      "    cmd, data = remote.recv()\n",
      "                ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 249, in recv\n",
      "    buf = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 413, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 382, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mapleleaf/Downloads/RL/Deep-Reinforcement-Learning-Algorithms/MountainCarContinuous_PPO/parallelEnv.py\", line 111, in worker\n",
      "    cmd, data = remote.recv()\n",
      "                ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 249, in recv\n",
      "    buf = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 413, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 382, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mapleleaf/Downloads/RL/Deep-Reinforcement-Learning-Algorithms/MountainCarContinuous_PPO/parallelEnv.py\", line 111, in worker\n",
      "    cmd, data = remote.recv()\n",
      "                ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 249, in recv\n",
      "    buf = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 413, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 382, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mapleleaf/Downloads/RL/Deep-Reinforcement-Learning-Algorithms/MountainCarContinuous_PPO/parallelEnv.py\", line 111, in worker\n",
      "    cmd, data = remote.recv()\n",
      "                ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 249, in recv\n",
      "    buf = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 413, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 382, in _recv\n",
      "    raise EOFError\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mapleleaf/Downloads/RL/Deep-Reinforcement-Learning-Algorithms/MountainCarContinuous_PPO/parallelEnv.py\", line 111, in worker\n",
      "    cmd, data = remote.recv()\n",
      "                ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 249, in recv\n",
      "    buf = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 413, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 382, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n",
      "EOFError\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mapleleaf/Downloads/RL/Deep-Reinforcement-Learning-Algorithms/MountainCarContinuous_PPO/parallelEnv.py\", line 111, in worker\n",
      "    cmd, data = remote.recv()\n",
      "                ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 249, in recv\n",
      "    buf = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 413, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 382, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mapleleaf/Downloads/RL/Deep-Reinforcement-Learning-Algorithms/MountainCarContinuous_PPO/parallelEnv.py\", line 111, in worker\n",
      "    cmd, data = remote.recv()\n",
      "                ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 249, in recv\n",
      "    buf = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 413, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 382, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents:  16\n",
      "Ep. 1, Timesteps 999, Score.Agents: -156.22, Avg.Score: -150.60, Time: 00:00:03, Interval: 00:03\n",
      "Ep. 2, Timesteps 999, Score.Agents: -147.53, Avg.Score: -149.58, Time: 00:00:04, Interval: 00:01\n",
      "Ep. 3, Timesteps 999, Score.Agents: -152.82, Avg.Score: -150.39, Time: 00:00:05, Interval: 00:01\n",
      "Ep. 4, Timesteps 999, Score.Agents: -137.76, Avg.Score: -147.86, Time: 00:00:07, Interval: 00:02\n",
      "Ep. 5, Timesteps 999, Score.Agents: -134.05, Avg.Score: -145.56, Time: 00:00:08, Interval: 00:01\n",
      "Ep. 6, Timesteps 999, Score.Agents: -147.40, Avg.Score: -145.82, Time: 00:00:09, Interval: 00:01\n",
      "Ep. 7, Timesteps 999, Score.Agents: -124.42, Avg.Score: -143.15, Time: 00:00:10, Interval: 00:01\n",
      "Ep. 8, Timesteps 999, Score.Agents: -110.38, Avg.Score: -139.51, Time: 00:00:12, Interval: 00:02\n",
      "Ep. 9, Timesteps 999, Score.Agents: -85.45, Avg.Score: -134.10, Time: 00:00:13, Interval: 00:01\n",
      "Ep. 10, Timesteps 999, Score.Agents: -76.77, Avg.Score: -128.89, Time: 00:00:14, Interval: 00:01\n",
      "Ep. 11, Timesteps 999, Score.Agents: -73.81, Avg.Score: -124.30, Time: 00:00:16, Interval: 00:02\n",
      "Ep. 12, Timesteps 999, Score.Agents: -129.93, Avg.Score: -124.73, Time: 00:00:17, Interval: 00:01\n",
      "Ep. 13, Timesteps 999, Score.Agents: -112.28, Avg.Score: -123.84, Time: 00:00:18, Interval: 00:01\n",
      "Ep. 14, Timesteps 999, Score.Agents: -121.93, Avg.Score: -123.72, Time: 00:00:19, Interval: 00:01\n",
      "Ep. 15, Timesteps 999, Score.Agents: -118.07, Avg.Score: -123.36, Time: 00:00:21, Interval: 00:02\n",
      "Ep. 16, Timesteps 999, Score.Agents: -111.45, Avg.Score: -122.66, Time: 00:00:22, Interval: 00:01\n",
      "Ep. 17, Timesteps 999, Score.Agents: -110.69, Avg.Score: -122.00, Time: 00:00:23, Interval: 00:01\n",
      "Ep. 18, Timesteps 999, Score.Agents: -101.83, Avg.Score: -120.94, Time: 00:00:25, Interval: 00:02\n",
      "Ep. 19, Timesteps 999, Score.Agents: -92.67, Avg.Score: -119.52, Time: 00:00:26, Interval: 00:01\n",
      "Ep. 20, Timesteps 999, Score.Agents: -97.20, Avg.Score: -118.46, Time: 00:00:27, Interval: 00:01\n",
      "Ep. 21, Timesteps 999, Score.Agents: -89.87, Avg.Score: -117.16, Time: 00:00:28, Interval: 00:01\n",
      "Ep. 22, Timesteps 999, Score.Agents: -90.17, Avg.Score: -115.99, Time: 00:00:30, Interval: 00:02\n",
      "Ep. 23, Timesteps 999, Score.Agents: -99.89, Avg.Score: -115.32, Time: 00:00:31, Interval: 00:01\n",
      "Ep. 24, Timesteps 999, Score.Agents: -76.70, Avg.Score: -113.77, Time: 00:00:32, Interval: 00:01\n",
      "Ep. 25, Timesteps 999, Score.Agents: -88.01, Avg.Score: -112.78, Time: 00:00:33, Interval: 00:01\n",
      "Ep. 26, Timesteps 999, Score.Agents: -70.65, Avg.Score: -111.22, Time: 00:00:35, Interval: 00:02\n",
      "Ep. 27, Timesteps 999, Score.Agents: -81.06, Avg.Score: -110.14, Time: 00:00:36, Interval: 00:01\n",
      "Ep. 28, Timesteps 999, Score.Agents: -73.57, Avg.Score: -108.88, Time: 00:00:37, Interval: 00:01\n",
      "Ep. 29, Timesteps 999, Score.Agents: -63.20, Avg.Score: -107.36, Time: 00:00:39, Interval: 00:02\n",
      "Saving model, i_episode:  30 \n",
      "\n",
      "Ep. 30, Timesteps 999, Score.Agents: -49.58, Avg.Score: -105.50, Time: 00:00:40, Interval: 00:01\n",
      "Ep. 31, Timesteps 999, Score.Agents: -68.55, Avg.Score: -104.34, Time: 00:00:41, Interval: 00:01\n",
      "Ep. 32, Timesteps 999, Score.Agents: -97.77, Avg.Score: -104.14, Time: 00:00:42, Interval: 00:01\n",
      "Ep. 33, Timesteps 999, Score.Agents: 111.04, Avg.Score: -97.81, Time: 00:00:44, Interval: 00:02\n",
      "Ep. 34, Timesteps 999, Score.Agents: 48.10, Avg.Score: -93.64, Time: 00:00:45, Interval: 00:01\n",
      "Ep. 35, Timesteps 999, Score.Agents: 149.45, Avg.Score: -86.89, Time: 00:00:46, Interval: 00:01\n",
      "Ep. 36, Timesteps 999, Score.Agents: 322.01, Avg.Score: -75.84, Time: 00:00:47, Interval: 00:01\n",
      "Ep. 37, Timesteps 999, Score.Agents: 438.27, Avg.Score: -62.31, Time: 00:00:49, Interval: 00:02\n",
      "Ep. 38, Timesteps 999, Score.Agents: 525.56, Avg.Score: -47.24, Time: 00:00:50, Interval: 00:01\n",
      "Ep. 39, Timesteps 999, Score.Agents: 504.11, Avg.Score: -33.45, Time: 00:00:51, Interval: 00:01\n",
      "Ep. 40, Timesteps 999, Score.Agents: 529.49, Avg.Score: -19.72, Time: 00:00:53, Interval: 00:02\n",
      "Ep. 41, Timesteps 999, Score.Agents: 776.28, Avg.Score: -0.77, Time: 00:00:54, Interval: 00:01\n",
      "Ep. 42, Timesteps 999, Score.Agents: 698.20, Avg.Score: 15.48, Time: 00:00:55, Interval: 00:01\n",
      "Ep. 43, Timesteps 999, Score.Agents: 762.69, Avg.Score: 32.47, Time: 00:00:57, Interval: 00:02\n",
      "Ep. 44, Timesteps 999, Score.Agents: 791.09, Avg.Score: 49.32, Time: 00:00:58, Interval: 00:01\n",
      "Ep. 45, Timesteps 999, Score.Agents: 695.33, Avg.Score: 63.37, Time: 00:00:59, Interval: 00:01\n",
      "Ep. 46, Timesteps 999, Score.Agents: 738.94, Avg.Score: 77.74, Time: 00:01:01, Interval: 00:02\n",
      "Ep. 47, Timesteps 999, Score.Agents: 688.32, Avg.Score: 90.46, Time: 00:01:02, Interval: 00:01\n",
      "Ep. 48, Timesteps 999, Score.Agents: 843.11, Avg.Score: 105.82, Time: 00:01:03, Interval: 00:01\n",
      "Ep. 49, Timesteps 999, Score.Agents: 415.52, Avg.Score: 112.02, Time: 00:01:04, Interval: 00:01\n",
      "Ep. 50, Timesteps 999, Score.Agents: 620.36, Avg.Score: 121.98, Time: 00:01:06, Interval: 00:02\n",
      "Ep. 51, Timesteps 999, Score.Agents: 754.95, Avg.Score: 134.16, Time: 00:01:07, Interval: 00:01\n",
      "Ep. 52, Timesteps 999, Score.Agents: 757.08, Avg.Score: 145.91, Time: 00:01:08, Interval: 00:01\n",
      "Ep. 53, Timesteps 999, Score.Agents: 852.18, Avg.Score: 158.99, Time: 00:01:10, Interval: 00:02\n",
      "Ep. 54, Timesteps 999, Score.Agents: 1078.62, Avg.Score: 175.71, Time: 00:01:11, Interval: 00:01\n",
      "Ep. 55, Timesteps 999, Score.Agents: 651.15, Avg.Score: 184.20, Time: 00:01:12, Interval: 00:01\n",
      "Ep. 56, Timesteps 999, Score.Agents: 656.90, Avg.Score: 192.49, Time: 00:01:14, Interval: 00:02\n",
      "Ep. 57, Timesteps 999, Score.Agents: 841.39, Avg.Score: 203.68, Time: 00:01:15, Interval: 00:01\n",
      "Ep. 58, Timesteps 999, Score.Agents: 844.97, Avg.Score: 214.55, Time: 00:01:16, Interval: 00:01\n",
      "Ep. 59, Timesteps 999, Score.Agents: -557.24, Avg.Score: 201.69, Time: 00:01:17, Interval: 00:01\n",
      "Saving model, i_episode:  60 \n",
      "\n",
      "Ep. 60, Timesteps 999, Score.Agents: -555.46, Avg.Score: 189.27, Time: 00:01:19, Interval: 00:02\n",
      "Ep. 61, Timesteps 999, Score.Agents: -504.60, Avg.Score: 178.08, Time: 00:01:20, Interval: 00:01\n",
      "Ep. 62, Timesteps 999, Score.Agents: -455.31, Avg.Score: 168.03, Time: 00:01:21, Interval: 00:01\n",
      "Ep. 63, Timesteps 999, Score.Agents: -417.87, Avg.Score: 158.87, Time: 00:01:23, Interval: 00:02\n",
      "Ep. 64, Timesteps 999, Score.Agents: -415.38, Avg.Score: 150.04, Time: 00:01:24, Interval: 00:01\n",
      "Ep. 65, Timesteps 999, Score.Agents: -364.63, Avg.Score: 142.24, Time: 00:01:25, Interval: 00:01\n",
      "Ep. 66, Timesteps 999, Score.Agents: -347.54, Avg.Score: 134.93, Time: 00:01:26, Interval: 00:01\n",
      "Ep. 67, Timesteps 999, Score.Agents: -323.88, Avg.Score: 128.18, Time: 00:01:28, Interval: 00:02\n",
      "Ep. 68, Timesteps 999, Score.Agents: -303.41, Avg.Score: 121.93, Time: 00:01:29, Interval: 00:01\n",
      "Ep. 69, Timesteps 999, Score.Agents: -270.61, Avg.Score: 116.32, Time: 00:01:30, Interval: 00:01\n",
      "Ep. 70, Timesteps 999, Score.Agents: -273.87, Avg.Score: 110.83, Time: 00:01:32, Interval: 00:02\n",
      "Ep. 71, Timesteps 999, Score.Agents: -242.00, Avg.Score: 105.93, Time: 00:01:33, Interval: 00:01\n",
      "Ep. 72, Timesteps 999, Score.Agents: -228.77, Avg.Score: 101.34, Time: 00:01:34, Interval: 00:01\n",
      "Ep. 73, Timesteps 999, Score.Agents: -204.10, Avg.Score: 97.21, Time: 00:01:36, Interval: 00:02\n",
      "Ep. 74, Timesteps 999, Score.Agents: -172.16, Avg.Score: 93.62, Time: 00:01:37, Interval: 00:01\n",
      "Ep. 75, Timesteps 999, Score.Agents: -186.15, Avg.Score: 89.94, Time: 00:01:38, Interval: 00:01\n",
      "Ep. 76, Timesteps 999, Score.Agents: -152.02, Avg.Score: 86.80, Time: 00:01:39, Interval: 00:01\n",
      "Ep. 77, Timesteps 999, Score.Agents: -162.42, Avg.Score: 83.60, Time: 00:01:41, Interval: 00:02\n",
      "Ep. 78, Timesteps 999, Score.Agents: -178.39, Avg.Score: 80.29, Time: 00:01:42, Interval: 00:01\n",
      "Ep. 79, Timesteps 999, Score.Agents: -151.97, Avg.Score: 77.38, Time: 00:01:43, Interval: 00:01\n",
      "Ep. 80, Timesteps 999, Score.Agents: -162.28, Avg.Score: 74.42, Time: 00:01:45, Interval: 00:02\n",
      "Ep. 81, Timesteps 999, Score.Agents: -139.48, Avg.Score: 71.82, Time: 00:01:46, Interval: 00:01\n",
      "Ep. 82, Timesteps 999, Score.Agents: -151.42, Avg.Score: 69.13, Time: 00:01:47, Interval: 00:01\n",
      "Ep. 83, Timesteps 999, Score.Agents: -138.10, Avg.Score: 66.66, Time: 00:01:49, Interval: 00:02\n",
      "Ep. 84, Timesteps 999, Score.Agents: -135.43, Avg.Score: 64.28, Time: 00:01:50, Interval: 00:01\n",
      "Ep. 85, Timesteps 999, Score.Agents: -118.09, Avg.Score: 62.16, Time: 00:01:51, Interval: 00:01\n",
      "Ep. 86, Timesteps 999, Score.Agents: -115.08, Avg.Score: 60.12, Time: 00:01:52, Interval: 00:01\n",
      "Ep. 87, Timesteps 999, Score.Agents: -118.83, Avg.Score: 58.09, Time: 00:01:54, Interval: 00:02\n",
      "Ep. 88, Timesteps 999, Score.Agents: -102.62, Avg.Score: 56.28, Time: 00:01:55, Interval: 00:01\n",
      "Ep. 89, Timesteps 999, Score.Agents: -90.94, Avg.Score: 54.65, Time: 00:01:56, Interval: 00:01\n",
      "Saving model, i_episode:  90 \n",
      "\n",
      "Ep. 90, Timesteps 999, Score.Agents: -93.17, Avg.Score: 53.02, Time: 00:01:58, Interval: 00:02\n",
      "Ep. 91, Timesteps 999, Score.Agents: -81.00, Avg.Score: 51.57, Time: 00:01:59, Interval: 00:01\n",
      "Ep. 92, Timesteps 999, Score.Agents: -87.46, Avg.Score: 50.07, Time: 00:02:00, Interval: 00:01\n",
      "Ep. 93, Timesteps 999, Score.Agents: -103.30, Avg.Score: 48.44, Time: 00:02:02, Interval: 00:02\n",
      "Ep. 94, Timesteps 999, Score.Agents: -87.73, Avg.Score: 47.01, Time: 00:02:03, Interval: 00:01\n",
      "Ep. 95, Timesteps 999, Score.Agents: -84.24, Avg.Score: 45.64, Time: 00:02:04, Interval: 00:01\n",
      "Ep. 96, Timesteps 999, Score.Agents: -191.27, Avg.Score: 43.20, Time: 00:02:06, Interval: 00:02\n",
      "Ep. 97, Timesteps 999, Score.Agents: -52.60, Avg.Score: 42.22, Time: 00:02:07, Interval: 00:01\n",
      "Ep. 98, Timesteps 999, Score.Agents: -79.72, Avg.Score: 40.99, Time: 00:02:08, Interval: 00:01\n",
      "Ep. 99, Timesteps 999, Score.Agents: -29.39, Avg.Score: 40.28, Time: 00:02:10, Interval: 00:02\n",
      "Ep. 100, Timesteps 999, Score.Agents: -845.41, Avg.Score: 33.28, Time: 00:02:11, Interval: 00:01\n",
      "Ep. 101, Timesteps 999, Score.Agents: -883.71, Avg.Score: 26.01, Time: 00:02:12, Interval: 00:01\n",
      "Ep. 102, Timesteps 999, Score.Agents: -969.82, Avg.Score: 17.78, Time: 00:02:14, Interval: 00:02\n",
      "Ep. 103, Timesteps 999, Score.Agents: -931.84, Avg.Score: 9.99, Time: 00:02:15, Interval: 00:01\n",
      "Ep. 104, Timesteps 999, Score.Agents: -1263.03, Avg.Score: -1.26, Time: 00:02:16, Interval: 00:01\n",
      "Ep. 105, Timesteps 999, Score.Agents: -1692.24, Avg.Score: -16.84, Time: 00:02:18, Interval: 00:02\n",
      "Ep. 106, Timesteps 999, Score.Agents: -1716.79, Avg.Score: -32.54, Time: 00:02:19, Interval: 00:01\n",
      "Ep. 107, Timesteps 999, Score.Agents: -1660.68, Avg.Score: -47.90, Time: 00:02:20, Interval: 00:01\n",
      "Ep. 108, Timesteps 999, Score.Agents: -1607.31, Avg.Score: -62.87, Time: 00:02:22, Interval: 00:02\n",
      "Ep. 109, Timesteps 999, Score.Agents: -1593.17, Avg.Score: -77.95, Time: 00:02:23, Interval: 00:01\n",
      "Ep. 110, Timesteps 999, Score.Agents: -1353.47, Avg.Score: -90.71, Time: 00:02:24, Interval: 00:01\n",
      "Ep. 111, Timesteps 999, Score.Agents: -1331.70, Avg.Score: -103.29, Time: 00:02:26, Interval: 00:02\n",
      "Ep. 112, Timesteps 999, Score.Agents: -1265.81, Avg.Score: -114.65, Time: 00:02:27, Interval: 00:01\n",
      "Ep. 113, Timesteps 999, Score.Agents: -1213.60, Avg.Score: -125.66, Time: 00:02:28, Interval: 00:01\n",
      "Ep. 114, Timesteps 999, Score.Agents: -1154.88, Avg.Score: -135.99, Time: 00:02:30, Interval: 00:02\n",
      "Ep. 115, Timesteps 999, Score.Agents: -1137.49, Avg.Score: -146.19, Time: 00:02:31, Interval: 00:01\n",
      "Ep. 116, Timesteps 999, Score.Agents: -1086.96, Avg.Score: -155.94, Time: 00:02:32, Interval: 00:01\n",
      "Ep. 117, Timesteps 999, Score.Agents: -1039.78, Avg.Score: -165.23, Time: 00:02:33, Interval: 00:01\n",
      "Ep. 118, Timesteps 999, Score.Agents: -977.27, Avg.Score: -173.99, Time: 00:02:35, Interval: 00:02\n",
      "Ep. 119, Timesteps 999, Score.Agents: -945.41, Avg.Score: -182.51, Time: 00:02:36, Interval: 00:01\n"
     ]
    }
   ],
   "source": [
    "envs = parallelEnv('MountainCarContinuous-v0', n=num_processes, seed=seed, dense=True)\n",
    "scores, avg_scores = ppo_vec_env_train(envs, agent, policy, num_processes, max_steps, rollouts)\n",
    "save(model=policy,directory=dir_chk,filename='we0',suffix='pre_train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Process Process-32:\n",
      "Process Process-31:\n",
      "Process Process-29:\n",
      "Process Process-30:\n",
      "Process Process-28:\n",
      "Process Process-27:\n",
      "Process Process-26:\n",
      "Process Process-25:\n",
      "Process Process-24:\n",
      "Process Process-23:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mapleleaf/Downloads/RL/Deep-Reinforcement-Learning-Algorithms/MountainCarContinuous_PPO/parallelEnv.py\", line 111, in worker\n",
      "    cmd, data = remote.recv()\n",
      "                ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 249, in recv\n",
      "    buf = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 413, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 382, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mapleleaf/Downloads/RL/Deep-Reinforcement-Learning-Algorithms/MountainCarContinuous_PPO/parallelEnv.py\", line 111, in worker\n",
      "    cmd, data = remote.recv()\n",
      "                ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 249, in recv\n",
      "    buf = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 413, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 382, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n",
      "Process Process-22:\n",
      "Process Process-20:\n",
      "Process Process-19:\n",
      "Process Process-18:\n",
      "Process Process-21:\n",
      "Process Process-17:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mapleleaf/Downloads/RL/Deep-Reinforcement-Learning-Algorithms/MountainCarContinuous_PPO/parallelEnv.py\", line 111, in worker\n",
      "    cmd, data = remote.recv()\n",
      "                ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 249, in recv\n",
      "    buf = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 413, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 382, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mapleleaf/Downloads/RL/Deep-Reinforcement-Learning-Algorithms/MountainCarContinuous_PPO/parallelEnv.py\", line 111, in worker\n",
      "    cmd, data = remote.recv()\n",
      "                ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 249, in recv\n",
      "    buf = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 413, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 382, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mapleleaf/Downloads/RL/Deep-Reinforcement-Learning-Algorithms/MountainCarContinuous_PPO/parallelEnv.py\", line 111, in worker\n",
      "    cmd, data = remote.recv()\n",
      "                ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 249, in recv\n",
      "    buf = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 413, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 382, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mapleleaf/Downloads/RL/Deep-Reinforcement-Learning-Algorithms/MountainCarContinuous_PPO/parallelEnv.py\", line 111, in worker\n",
      "    cmd, data = remote.recv()\n",
      "                ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 249, in recv\n",
      "    buf = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 413, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 382, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mapleleaf/Downloads/RL/Deep-Reinforcement-Learning-Algorithms/MountainCarContinuous_PPO/parallelEnv.py\", line 111, in worker\n",
      "    cmd, data = remote.recv()\n",
      "                ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 249, in recv\n",
      "    buf = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 413, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 382, in _recv\n",
      "    raise EOFError\n",
      "Traceback (most recent call last):\n",
      "EOFError\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mapleleaf/Downloads/RL/Deep-Reinforcement-Learning-Algorithms/MountainCarContinuous_PPO/parallelEnv.py\", line 111, in worker\n",
      "    cmd, data = remote.recv()\n",
      "                ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 249, in recv\n",
      "    buf = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 413, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 382, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mapleleaf/Downloads/RL/Deep-Reinforcement-Learning-Algorithms/MountainCarContinuous_PPO/parallelEnv.py\", line 111, in worker\n",
      "    cmd, data = remote.recv()\n",
      "                ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 249, in recv\n",
      "    buf = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 413, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 382, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mapleleaf/Downloads/RL/Deep-Reinforcement-Learning-Algorithms/MountainCarContinuous_PPO/parallelEnv.py\", line 111, in worker\n",
      "    cmd, data = remote.recv()\n",
      "                ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 249, in recv\n",
      "    buf = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 413, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 382, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mapleleaf/Downloads/RL/Deep-Reinforcement-Learning-Algorithms/MountainCarContinuous_PPO/parallelEnv.py\", line 111, in worker\n",
      "    cmd, data = remote.recv()\n",
      "                ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 249, in recv\n",
      "    buf = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 413, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 382, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mapleleaf/Downloads/RL/Deep-Reinforcement-Learning-Algorithms/MountainCarContinuous_PPO/parallelEnv.py\", line 111, in worker\n",
      "    cmd, data = remote.recv()\n",
      "                ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 249, in recv\n",
      "    buf = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 413, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 382, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mapleleaf/Downloads/RL/Deep-Reinforcement-Learning-Algorithms/MountainCarContinuous_PPO/parallelEnv.py\", line 111, in worker\n",
      "    cmd, data = remote.recv()\n",
      "                ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 249, in recv\n",
      "    buf = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 413, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 382, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mapleleaf/Downloads/RL/Deep-Reinforcement-Learning-Algorithms/MountainCarContinuous_PPO/parallelEnv.py\", line 111, in worker\n",
      "    cmd, data = remote.recv()\n",
      "                ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 249, in recv\n",
      "    buf = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 413, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 382, in _recv\n",
      "    raise EOFError\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mapleleaf/Downloads/RL/Deep-Reinforcement-Learning-Algorithms/MountainCarContinuous_PPO/parallelEnv.py\", line 111, in worker\n",
      "    cmd, data = remote.recv()\n",
      "                ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 249, in recv\n",
      "    buf = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 413, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 382, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n",
      "EOFError\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/mapleleaf/Downloads/RL/Deep-Reinforcement-Learning-Algorithms/MountainCarContinuous_PPO/parallelEnv.py\", line 111, in worker\n",
      "    cmd, data = remote.recv()\n",
      "                ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 249, in recv\n",
      "    buf = self._recv_bytes()\n",
      "          ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 413, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "          ^^^^^^^^^^^^^\n",
      "  File \"/Users/mapleleaf/anaconda3/lib/python3.11/multiprocessing/connection.py\", line 382, in _recv\n",
      "    raise EOFError\n",
      "EOFError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents:  16\n",
      "Ep. 1, Timesteps 999, Score.Agents: -893.58, Avg.Score: -894.07, Time: 00:00:02, Interval: 00:02\n",
      "Ep. 2, Timesteps 999, Score.Agents: -893.12, Avg.Score: -893.76, Time: 00:00:03, Interval: 00:01\n",
      "Ep. 3, Timesteps 999, Score.Agents: -897.84, Avg.Score: -894.78, Time: 00:00:04, Interval: 00:01\n",
      "Ep. 4, Timesteps 999, Score.Agents: -894.00, Avg.Score: -894.62, Time: 00:00:06, Interval: 00:02\n",
      "Ep. 5, Timesteps 999, Score.Agents: -892.95, Avg.Score: -894.34, Time: 00:00:07, Interval: 00:01\n",
      "Ep. 6, Timesteps 999, Score.Agents: -895.05, Avg.Score: -894.44, Time: 00:00:08, Interval: 00:01\n",
      "Ep. 7, Timesteps 999, Score.Agents: -893.53, Avg.Score: -894.33, Time: 00:00:09, Interval: 00:01\n",
      "Ep. 8, Timesteps 999, Score.Agents: -898.85, Avg.Score: -894.83, Time: 00:00:10, Interval: 00:01\n",
      "Ep. 9, Timesteps 999, Score.Agents: -892.83, Avg.Score: -894.63, Time: 00:00:12, Interval: 00:02\n",
      "Ep. 10, Timesteps 999, Score.Agents: -895.30, Avg.Score: -894.69, Time: 00:00:13, Interval: 00:01\n",
      "Ep. 11, Timesteps 999, Score.Agents: -893.94, Avg.Score: -894.63, Time: 00:00:14, Interval: 00:01\n",
      "Ep. 12, Timesteps 999, Score.Agents: -894.06, Avg.Score: -894.59, Time: 00:00:15, Interval: 00:01\n",
      "Ep. 13, Timesteps 999, Score.Agents: -893.41, Avg.Score: -894.50, Time: 00:00:17, Interval: 00:02\n",
      "Ep. 14, Timesteps 999, Score.Agents: -895.99, Avg.Score: -894.60, Time: 00:00:18, Interval: 00:01\n",
      "Ep. 15, Timesteps 999, Score.Agents: -888.57, Avg.Score: -894.22, Time: 00:00:19, Interval: 00:01\n",
      "Ep. 16, Timesteps 999, Score.Agents: -892.37, Avg.Score: -894.12, Time: 00:00:20, Interval: 00:01\n",
      "Ep. 17, Timesteps 999, Score.Agents: -895.07, Avg.Score: -894.17, Time: 00:00:22, Interval: 00:02\n",
      "Ep. 18, Timesteps 999, Score.Agents: -892.18, Avg.Score: -894.06, Time: 00:00:23, Interval: 00:01\n",
      "Ep. 19, Timesteps 999, Score.Agents: -896.65, Avg.Score: -894.19, Time: 00:00:24, Interval: 00:01\n",
      "Ep. 20, Timesteps 999, Score.Agents: -895.32, Avg.Score: -894.25, Time: 00:00:25, Interval: 00:01\n",
      "Ep. 21, Timesteps 999, Score.Agents: -894.33, Avg.Score: -894.25, Time: 00:00:26, Interval: 00:01\n",
      "Ep. 22, Timesteps 999, Score.Agents: -892.52, Avg.Score: -894.18, Time: 00:00:28, Interval: 00:02\n",
      "Ep. 23, Timesteps 999, Score.Agents: -893.35, Avg.Score: -894.14, Time: 00:00:29, Interval: 00:01\n",
      "Ep. 24, Timesteps 999, Score.Agents: -894.39, Avg.Score: -894.15, Time: 00:00:30, Interval: 00:01\n",
      "Ep. 25, Timesteps 999, Score.Agents: -898.64, Avg.Score: -894.32, Time: 00:00:31, Interval: 00:01\n",
      "Ep. 26, Timesteps 999, Score.Agents: -895.97, Avg.Score: -894.38, Time: 00:00:32, Interval: 00:01\n",
      "Ep. 27, Timesteps 999, Score.Agents: -892.22, Avg.Score: -894.31, Time: 00:00:34, Interval: 00:02\n",
      "Ep. 28, Timesteps 999, Score.Agents: -895.76, Avg.Score: -894.36, Time: 00:00:35, Interval: 00:01\n",
      "Ep. 29, Timesteps 999, Score.Agents: -892.34, Avg.Score: -894.29, Time: 00:00:36, Interval: 00:01\n",
      "Saving model, i_episode:  30 \n",
      "\n",
      "Ep. 30, Timesteps 999, Score.Agents: -892.41, Avg.Score: -894.23, Time: 00:00:37, Interval: 00:01\n",
      "Ep. 31, Timesteps 999, Score.Agents: -896.65, Avg.Score: -894.30, Time: 00:00:38, Interval: 00:01\n",
      "Ep. 32, Timesteps 999, Score.Agents: -896.64, Avg.Score: -894.38, Time: 00:00:40, Interval: 00:02\n",
      "Ep. 33, Timesteps 999, Score.Agents: -893.58, Avg.Score: -894.35, Time: 00:00:41, Interval: 00:01\n",
      "Ep. 34, Timesteps 999, Score.Agents: -896.29, Avg.Score: -894.41, Time: 00:00:42, Interval: 00:01\n",
      "Ep. 35, Timesteps 999, Score.Agents: -896.26, Avg.Score: -894.46, Time: 00:00:44, Interval: 00:02\n",
      "Ep. 36, Timesteps 999, Score.Agents: -892.91, Avg.Score: -894.42, Time: 00:00:45, Interval: 00:01\n",
      "Ep. 37, Timesteps 999, Score.Agents: -894.72, Avg.Score: -894.43, Time: 00:00:46, Interval: 00:01\n",
      "Ep. 38, Timesteps 999, Score.Agents: -896.37, Avg.Score: -894.48, Time: 00:00:47, Interval: 00:01\n",
      "Ep. 39, Timesteps 999, Score.Agents: -894.98, Avg.Score: -894.49, Time: 00:00:48, Interval: 00:01\n",
      "Ep. 40, Timesteps 999, Score.Agents: -898.86, Avg.Score: -894.59, Time: 00:00:50, Interval: 00:02\n",
      "Ep. 41, Timesteps 999, Score.Agents: -895.06, Avg.Score: -894.61, Time: 00:00:51, Interval: 00:01\n",
      "Ep. 42, Timesteps 999, Score.Agents: -900.34, Avg.Score: -894.74, Time: 00:00:52, Interval: 00:01\n",
      "Ep. 43, Timesteps 999, Score.Agents: -892.14, Avg.Score: -894.68, Time: 00:00:53, Interval: 00:01\n",
      "Ep. 44, Timesteps 999, Score.Agents: -892.99, Avg.Score: -894.64, Time: 00:00:54, Interval: 00:01\n",
      "Ep. 45, Timesteps 999, Score.Agents: -897.45, Avg.Score: -894.70, Time: 00:00:55, Interval: 00:01\n",
      "Ep. 46, Timesteps 999, Score.Agents: -893.39, Avg.Score: -894.68, Time: 00:00:57, Interval: 00:02\n",
      "Ep. 47, Timesteps 999, Score.Agents: -896.30, Avg.Score: -894.71, Time: 00:00:58, Interval: 00:01\n",
      "Ep. 48, Timesteps 999, Score.Agents: -896.34, Avg.Score: -894.74, Time: 00:00:59, Interval: 00:01\n",
      "Ep. 49, Timesteps 999, Score.Agents: -894.98, Avg.Score: -894.75, Time: 00:01:00, Interval: 00:01\n"
     ]
    }
   ],
   "source": [
    "envs = parallelEnv('MountainCarContinuous-v0', n=num_processes, seed=seed, dense=False)\n",
    "num_updates=50\n",
    "gamma = 0.99\n",
    "tau=0.95\n",
    "save_interval=30\n",
    "log_interval= 1 \n",
    "\n",
    "def ppo_vec_env_train_critic(envs, agent, policy, num_processes, num_steps, rollouts):\n",
    "    \n",
    "    time_start = time.time()\n",
    "    \n",
    "    n=len(envs.ps)    \n",
    "    envs.reset()\n",
    "    \n",
    "    # start all parallel agents\n",
    "    print('Number of agents: ', n)\n",
    "    envs.step([[1]*4]*n)\n",
    "    \n",
    "    indices = []\n",
    "    for i  in range(n):\n",
    "        indices.append(i)\n",
    "     \n",
    "    s = 0\n",
    "    \n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores_array = []\n",
    "    avg_scores_array = []    \n",
    "\n",
    "    for i_episode in range(num_updates):\n",
    "        \n",
    "        total_reward = np.zeros(n)\n",
    "        timestep = 0\n",
    "        \n",
    "        done = False\n",
    "        \n",
    "        for timestep in range(num_steps):\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                value, actions, action_log_prob, recurrent_hidden_states = \\\n",
    "                   policy.act(\n",
    "                        rollouts.obs[timestep],\n",
    "                        rollouts.recurrent_hidden_states[timestep],\n",
    "                        rollouts.masks[timestep])\n",
    "                   \n",
    "                \n",
    "            obs, rewards, done, _ = envs.step(actions.cpu().detach().numpy())\n",
    "            \n",
    "            \n",
    "            total_reward += rewards  ## this is the list by agents\n",
    "                        \n",
    "            # If done then clean the history of observations.\n",
    "            masks = torch.FloatTensor([[0.0] if done_ else [1.0] for done_ in done])\n",
    "            obs_t = torch.tensor(obs)\n",
    "            \n",
    "            ## Add one dimnesion to tensor, \n",
    "            ## This is (unsqueeze(1)) solution for:\n",
    "            ## RuntimeError: The expanded size of the tensor (1) must match the existing size...\n",
    "            rewards_t = torch.tensor(rewards).unsqueeze(1)\n",
    "            rollouts.insert(obs_t, recurrent_hidden_states, actions, action_log_prob, \\\n",
    "                value, rewards_t, masks)\n",
    "                                \n",
    "        avg_total_reward = np.mean(total_reward)\n",
    "        scores_deque.append(avg_total_reward)\n",
    "        scores_array.append(avg_total_reward)\n",
    "                \n",
    "        with torch.no_grad():\n",
    "            next_value = policy.get_value(rollouts.obs[-1],\n",
    "                            rollouts.recurrent_hidden_states[-1],\n",
    "                            rollouts.masks[-1]).detach()\n",
    "\n",
    "        rollouts.compute_returns(next_value, gamma, tau)\n",
    "        \n",
    "        agent.update_critic_only(rollouts)\n",
    "        # 改动了一下update\n",
    "        # agent.update(rollouts, i_episode)\n",
    "\n",
    "        rollouts.after_update()\n",
    "        \n",
    "        avg_score = np.mean(scores_deque)\n",
    "        avg_scores_array.append(avg_score)\n",
    "\n",
    "        if i_episode > 0 and i_episode % save_interval == 0:\n",
    "            print('Saving model, i_episode: ', i_episode, '\\n')\n",
    "            suf = return_suffix(avg_score)\n",
    "            save(policy, dir_chk, 'we0', suf)\n",
    "\n",
    "        \n",
    "        if i_episode % log_interval == 0 and len(scores_deque) > 1:            \n",
    "            prev_s = s\n",
    "            s = (int)(time.time() - time_start)\n",
    "            t_del = s - prev_s\n",
    "            print('Ep. {}, Timesteps {}, Score.Agents: {:.2f}, Avg.Score: {:.2f}, Time: {:02}:{:02}:{:02}, \\\n",
    "Interval: {:02}:{:02}'\\\n",
    "                   .format(i_episode, timestep+1, \\\n",
    "                        avg_total_reward, avg_score, s//3600, s%3600//60, s%60, t_del%3600//60, t_del%60)) \n",
    "    \n",
    "        if len(scores_deque) > 1 and avg_score > threshold:   \n",
    "            print('Environment solved with Average Score: ',  avg_score )\n",
    "            break\n",
    "        \n",
    "    \n",
    "    return scores_array, avg_scores_array\n",
    "\n",
    "scores, avg_scores = ppo_vec_env_train_critic(envs, agent, policy, num_processes, max_steps, rollouts)\n",
    "save(model=policy,directory=dir_chk,filename='we0',suffix='value_adjust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents:  16\n",
      "Ep. 1, Timesteps 999, Score.Agents: -853.03, Avg.Score: -873.09, Time: 00:00:02, Interval: 00:02\n",
      "Ep. 2, Timesteps 999, Score.Agents: -807.94, Avg.Score: -851.37, Time: 00:00:04, Interval: 00:02\n",
      "Ep. 3, Timesteps 999, Score.Agents: -781.41, Avg.Score: -833.88, Time: 00:00:05, Interval: 00:01\n",
      "Ep. 4, Timesteps 999, Score.Agents: -730.35, Avg.Score: -813.18, Time: 00:00:07, Interval: 00:02\n",
      "Ep. 5, Timesteps 999, Score.Agents: -700.59, Avg.Score: -794.41, Time: 00:00:08, Interval: 00:01\n",
      "Ep. 6, Timesteps 999, Score.Agents: -668.70, Avg.Score: -776.45, Time: 00:00:09, Interval: 00:01\n",
      "Ep. 7, Timesteps 999, Score.Agents: -626.93, Avg.Score: -757.76, Time: 00:00:10, Interval: 00:01\n",
      "Ep. 8, Timesteps 999, Score.Agents: -587.35, Avg.Score: -738.83, Time: 00:00:12, Interval: 00:02\n",
      "Ep. 9, Timesteps 999, Score.Agents: -565.24, Avg.Score: -721.47, Time: 00:00:13, Interval: 00:01\n",
      "Ep. 10, Timesteps 999, Score.Agents: -525.54, Avg.Score: -703.66, Time: 00:00:15, Interval: 00:02\n",
      "Ep. 11, Timesteps 999, Score.Agents: -503.85, Avg.Score: -687.01, Time: 00:00:16, Interval: 00:01\n",
      "Ep. 12, Timesteps 999, Score.Agents: -470.51, Avg.Score: -670.35, Time: 00:00:17, Interval: 00:01\n",
      "Ep. 13, Timesteps 999, Score.Agents: -438.94, Avg.Score: -653.82, Time: 00:00:18, Interval: 00:01\n",
      "Ep. 14, Timesteps 999, Score.Agents: -418.93, Avg.Score: -638.16, Time: 00:00:20, Interval: 00:02\n",
      "Ep. 15, Timesteps 999, Score.Agents: -389.77, Avg.Score: -622.64, Time: 00:00:21, Interval: 00:01\n",
      "Ep. 16, Timesteps 999, Score.Agents: -364.64, Avg.Score: -607.46, Time: 00:00:22, Interval: 00:01\n",
      "Ep. 17, Timesteps 999, Score.Agents: -343.89, Avg.Score: -592.82, Time: 00:00:24, Interval: 00:02\n",
      "Ep. 18, Timesteps 999, Score.Agents: -321.70, Avg.Score: -578.55, Time: 00:00:25, Interval: 00:01\n",
      "Ep. 19, Timesteps 999, Score.Agents: -302.96, Avg.Score: -564.77, Time: 00:00:27, Interval: 00:02\n",
      "Ep. 20, Timesteps 999, Score.Agents: -284.71, Avg.Score: -551.43, Time: 00:00:28, Interval: 00:01\n",
      "Ep. 21, Timesteps 999, Score.Agents: -271.46, Avg.Score: -538.71, Time: 00:00:29, Interval: 00:01\n",
      "Ep. 22, Timesteps 999, Score.Agents: -226.85, Avg.Score: -525.15, Time: 00:00:30, Interval: 00:01\n",
      "Ep. 23, Timesteps 999, Score.Agents: -226.97, Avg.Score: -512.73, Time: 00:00:32, Interval: 00:02\n",
      "Ep. 24, Timesteps 999, Score.Agents: -224.14, Avg.Score: -501.18, Time: 00:00:33, Interval: 00:01\n",
      "Ep. 25, Timesteps 999, Score.Agents: -215.37, Avg.Score: -490.19, Time: 00:00:34, Interval: 00:01\n",
      "Ep. 26, Timesteps 999, Score.Agents: -201.18, Avg.Score: -479.49, Time: 00:00:36, Interval: 00:02\n",
      "Ep. 27, Timesteps 999, Score.Agents: -189.15, Avg.Score: -469.12, Time: 00:00:37, Interval: 00:01\n",
      "Ep. 28, Timesteps 999, Score.Agents: -177.38, Avg.Score: -459.06, Time: 00:00:39, Interval: 00:02\n",
      "Ep. 29, Timesteps 999, Score.Agents: -167.93, Avg.Score: -449.35, Time: 00:00:40, Interval: 00:01\n",
      "Saving model, i_episode:  30 \n",
      "\n",
      "Ep. 30, Timesteps 999, Score.Agents: -136.00, Avg.Score: -439.24, Time: 00:00:41, Interval: 00:01\n",
      "Ep. 31, Timesteps 999, Score.Agents: -144.71, Avg.Score: -430.04, Time: 00:00:43, Interval: 00:02\n",
      "Ep. 32, Timesteps 999, Score.Agents: -137.86, Avg.Score: -421.19, Time: 00:00:44, Interval: 00:01\n",
      "Ep. 33, Timesteps 999, Score.Agents: -98.55, Avg.Score: -411.70, Time: 00:00:45, Interval: 00:01\n",
      "Ep. 34, Timesteps 999, Score.Agents: -77.63, Avg.Score: -402.15, Time: 00:00:47, Interval: 00:02\n",
      "Ep. 35, Timesteps 999, Score.Agents: -48.15, Avg.Score: -392.32, Time: 00:00:48, Interval: 00:01\n",
      "Ep. 36, Timesteps 999, Score.Agents: -68.11, Avg.Score: -383.56, Time: 00:00:49, Interval: 00:01\n",
      "Ep. 37, Timesteps 999, Score.Agents: -38.32, Avg.Score: -374.47, Time: 00:00:51, Interval: 00:02\n",
      "Ep. 38, Timesteps 999, Score.Agents: 58.47, Avg.Score: -363.37, Time: 00:00:52, Interval: 00:01\n",
      "Ep. 39, Timesteps 999, Score.Agents: -39.17, Avg.Score: -355.27, Time: 00:00:53, Interval: 00:01\n",
      "Ep. 40, Timesteps 999, Score.Agents: -47.32, Avg.Score: -347.75, Time: 00:00:55, Interval: 00:02\n",
      "Ep. 41, Timesteps 999, Score.Agents: 105.05, Avg.Score: -336.97, Time: 00:00:56, Interval: 00:01\n",
      "Ep. 42, Timesteps 999, Score.Agents: 131.56, Avg.Score: -326.08, Time: 00:00:57, Interval: 00:01\n",
      "Ep. 43, Timesteps 999, Score.Agents: 130.21, Avg.Score: -315.71, Time: 00:00:58, Interval: 00:01\n",
      "Ep. 44, Timesteps 999, Score.Agents: 123.15, Avg.Score: -305.95, Time: 00:01:00, Interval: 00:02\n",
      "Ep. 45, Timesteps 999, Score.Agents: 159.81, Avg.Score: -295.83, Time: 00:01:01, Interval: 00:01\n",
      "Ep. 46, Timesteps 999, Score.Agents: 186.82, Avg.Score: -285.56, Time: 00:01:02, Interval: 00:01\n",
      "Ep. 47, Timesteps 999, Score.Agents: 249.52, Avg.Score: -274.41, Time: 00:01:04, Interval: 00:02\n",
      "Ep. 48, Timesteps 999, Score.Agents: 243.57, Avg.Score: -263.84, Time: 00:01:05, Interval: 00:01\n",
      "Ep. 49, Timesteps 999, Score.Agents: 196.26, Avg.Score: -254.64, Time: 00:01:06, Interval: 00:01\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch.optim as optim\n",
    "agent.optimizer = optim.Adam(agent.actor_critic.parameters(), lr=0.003, eps=1e-5)\n",
    "num_updates=50\n",
    "scores, avg_scores = ppo_vec_env_train(envs, agent, policy, num_processes, max_steps, rollouts)\n",
    "save(model=policy,directory=dir_chk,filename='we0',suffix='final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of scores:  50 , len of avg_scores:  50\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print('length of scores: ', len(scores), ', len of avg_scores: ', len(avg_scores))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores, label=\"Score\")\n",
    "plt.plot(np.arange(1, len(avg_scores)+1), avg_scores, label=\"Avg on 100 episodes\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1)) \n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episodes #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
